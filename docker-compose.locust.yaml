version: "3.8"

services:
#----------------------------------------------------------------------------------------------------------------------------------------------------------------
  minio:
    container_name: Minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=supersecret
    image: quay.io/minio/minio:latest
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - ./minio:/data
    restart: unless-stopped
    networks:
      - my_network
    
    
#----------------------------------------------------------------------------------------------------------------------------------------------------------------
  metadata_mlflow:
    image: mysql:latest
    restart: always
    environment:
      MYSQL_DATABASE: 'db'
      # So you don't have to use root, but you can if you like
      MYSQL_USER: 'user'
      # You can use whatever password you like
      MYSQL_PASSWORD: 'password'
      # Password for root access
      MYSQL_ROOT_PASSWORD: 'password'
    ports:
      # <Port exposed> : <MySQL Port running inside container>
      - '3306:3306'
    expose:
      # Opens port 3306 on the container
      - '3306'
      # Where our data will be persisted
    container_name: metadata_mlflow
    volumes:
      - metadata-mlflow:/var/lib/mysql
    networks:
      - my_network

#----------------------------------------------------------------------------------------------------------------------------------------------------------------
  mlflow-service:
    build: ./mlflow
    container_name: mlflow-service
    ports:
      - "5000:5000"
    depends_on:
      - metadata_mlflow
      - minio
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: supersecret
    command: ["/mlflow/script.sh"]
    networks:
      - my_network
      

#----------------------------------------------------------------------------------------------------------------------------------------------------------------       
  api_service:
    #image: s4g0/locust_pruebas:inference 
    build: ./api-inference
    #ports:
    #  - "8989:89"
    deploy:
      mode: replicated
      replicas: 1

      resources:
        limits:
          cpus: '1'
          memory: 500M
        reservations:
          cpus: '0.25'
          memory: 200M
    # Comando para ejecutar la API con Uvicorn
    command: ["uv","run","uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8989"]
    networks:
      - my_network
    
    restart: always

#----------------------------------------------------------
  locust:
      build: ./locust
      container_name: locust
      ports:
        - "8089:8089"
      depends_on:
        - api_service
      environment:
        - LOCUST_HOST=http://api_service:8989
      networks:
      - my_network

#------------------------------    
  streamlit_app:
    build: ./Streamlit
    ports:
      - "8501:8501"
    depends_on:
      - api_service
    networks:
      - my_network
    restart: always

#--------------------    
# Names our volume
volumes:
  postgres-db-volume:
  metadata-mlflow:

networks:
  my_network:
    driver: bridge