{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401bd3fb-5582-4747-8516-e22371fbc326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28cedf-0059-4fbd-94d4-7aa147c443d9",
   "metadata": {},
   "source": [
    "# Funciones para enviar data a base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a474c20-d693-497c-b4cb-8520ddf8fce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------ Load raw data --------------------------------------\n",
    "def load_csv_to_mysql():\n",
    "    try:\n",
    "        csv_path = 'penguins_lter.csv'\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        engine = create_engine('mysql+pymysql://user:password@db:3306/db_jupyter')\n",
    "\n",
    "        # Guardar en MySQL\n",
    "        df.to_sql(\"penguins_original\", con=engine, if_exists='replace', index=False)\n",
    "        print(\"✅ Datos originales cargados en MySQL.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en load_csv_to_mysql: {e}\")\n",
    "\n",
    "# ------------------------------------ Load transformed data --------------------------------------\n",
    "def preprocesamiento():\n",
    "    try:\n",
    "        engine = create_engine(\"mysql+pymysql://user:password@db:3306/db_jupyter\")\n",
    "\n",
    "        # Leer los datos de MySQL con pd.read_sql en lugar de pd.read_sql_table\n",
    "        df = pd.read_sql(\"SELECT * FROM penguins_original\", con=engine)\n",
    "\n",
    "        # Transformación de \"Date Egg\" a día del año (manejo de NaN)\n",
    "        if \"Date Egg\" in df.columns:\n",
    "            df[\"Date Egg\"] = pd.to_datetime(df[\"Date Egg\"], errors=\"coerce\").dt.dayofyear\n",
    "            df[\"Date Egg\"].fillna(df[\"Date Egg\"].median(), inplace=True)\n",
    "\n",
    "        # Eliminar columnas irrelevantes si existen\n",
    "        cols_to_drop = [\"studyName\", \"Sample Number\", \"Individual ID\", \"Comments\"]\n",
    "        df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "        # Manejo de valores nulos en columnas numéricas\n",
    "        num_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n",
    "        for col in num_cols:\n",
    "            if col in df.columns:\n",
    "                df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "        # Manejo de valores nulos en columnas categóricas\n",
    "        cat_cols = [\"Species\", \"Region\", \"Island\", \"Stage\", \"Clutch Completion\", \"Sex\"]\n",
    "        for col in cat_cols:\n",
    "            if col in df.columns:\n",
    "                df[col].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "        # One-Hot Encoding para variables categóricas si existen\n",
    "        df = pd.get_dummies(df, columns=[col for col in cat_cols if col in df.columns], drop_first=True)\n",
    "\n",
    "        # Selección de variables predictoras y objetivo\n",
    "        feature_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"]\n",
    "        target_col = \"Body Mass (g)\"\n",
    "\n",
    "        if not all(col in df.columns for col in feature_cols + [target_col]):\n",
    "            raise ValueError(\"⚠️ Algunas columnas clave no están en los datos procesados.\")\n",
    "\n",
    "        X = df[feature_cols]\n",
    "        y = df[target_col]\n",
    "\n",
    "        # Dividir en entrenamiento y prueba (80%-20%)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Guardar los conjuntos en MySQL\n",
    "        X_train.to_sql(\"train_data_X\", con=engine, if_exists=\"replace\", index=False)\n",
    "        X_test.to_sql(\"test_data_X\", con=engine, if_exists=\"replace\", index=False)\n",
    "        y_train.to_sql(\"train_data_y\", con=engine, if_exists=\"replace\", index=False)\n",
    "        y_test.to_sql(\"test_data_y\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "        print(\"✅ Preprocesamiento completo. Tablas 'train_data_X', 'train_data_y', 'test_data_X' y 'test_data_y' creadas en MySQL.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en preprocesamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47398405-0a07-43c1-a1b2-9628a4fa18fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos originales cargados en MySQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22/328991044.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date Egg\"] = pd.to_datetime(df[\"Date Egg\"], errors=\"coerce\").dt.dayofyear\n",
      "/tmp/ipykernel_22/328991044.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Date Egg\"].fillna(df[\"Date Egg\"].median(), inplace=True)\n",
      "/tmp/ipykernel_22/328991044.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_22/328991044.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(\"Desconocido\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocesamiento completo. Tablas 'train_data_X', 'train_data_y', 'test_data_X' y 'test_data_y' creadas en MySQL.\n"
     ]
    }
   ],
   "source": [
    "#truncate_all_tables()\n",
    "load_csv_to_mysql()\n",
    "preprocesamiento()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5085b2f-57a1-4463-9c45-c8d427896d78",
   "metadata": {},
   "source": [
    "# Registrar modelos en MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25374ef-16e7-40bb-ade5-051e80cca9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://user:password@db:3306/db_jupyter\")\n",
    "\n",
    "    \n",
    "# Separar variables predictoras y objetivo\n",
    "X_train = pd.read_sql_table(\"train_data_X\", engine)\n",
    "y_train = pd.read_sql_table(\"train_data_y\", engine).values.ravel()\n",
    "X_test = pd.read_sql_table(\"test_data_X\", engine)\n",
    "y_test = pd.read_sql_table(\"test_data_y\", engine).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25b982b-056b-45e7-a5e6-4598b66ed996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Gradient_Boosting_looking_for_the_best_model active\n",
      "2 Random_forest_looking_for_the_best_model active\n",
      "1 mlflow_tracking_pinguins_proofs active\n",
      "0 Default active\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "for exp in client.search_experiments(view_type=\"ALL\"):\n",
    "    print(exp.experiment_id, exp.name, exp.lifecycle_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24d5057-f474-4a95-aa16-1a2b51180f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client.restore_experiment(experiment_id=\"1\")  # reemplaza con el ID real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41084c8-8764-44ec-a2ba-0d91163cc896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 15:00:34 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# connects to the Mlflow tracking server that you started above\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_pinguins_proofs\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"Random_forest_no_params\", description=desc) as run:\n",
    "    # Entrenar RandomForest\n",
    "    rf_model = RandomForestRegressor()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db45f92c-c411-4e27-86ef-afc583b56c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri: http://192.168.1.10:5000\n",
      "artifact uri: s3://mlflows3/artifacts/1/fab3ef7f93584a2b9c1bc633b506b72a/artifacts\n"
     ]
    }
   ],
   "source": [
    "print('tracking uri:', mlflow.get_tracking_uri())\n",
    "print('artifact uri:', mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e15e37-f713-413b-9c4e-cae2cf66c64b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 15:23:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# connects to the Mlflow tracking server that you started above\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_pinguins_proofs\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"Gradient_boost_no_params\", description=desc) as run:\n",
    "    # Entrenar GradietBoost\n",
    "    gb_model = GradientBoostingRegressor()\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    \n",
    "#mlflow.end_run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc1e60-d1a4-431e-b1a2-7d38a8479a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d8a1e56-f9aa-4732-930d-94f62c202435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 15:40:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/14 15:40:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/14 15:41:12 INFO mlflow.sklearn.utils: Logging the 5 best runs, 22 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "# connects to the Mlflow tracking server that you started above\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"Random_forest_looking_for_the_best_model\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"Random_forest_grid_search\"\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "searcher = GridSearchCV(estimator=rf_model, param_grid=params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_grid_search\") as run:\n",
    "    searcher.fit(X_train, y_train)\n",
    "    \n",
    "#mlflow.end_run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73623d3a-e244-46e6-bc31-2d13050d7b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 16:00:58 INFO mlflow.tracking.fluent: Experiment with name 'Gradient_Boosting_looking_for_the_best_model' does not exist. Creating a new experiment.\n",
      "2025/03/14 16:00:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/14 16:01:07 INFO mlflow.sklearn.utils: Logging the 5 best runs, 31 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "# connects to the Mlflow tracking server that you started above\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"Gradient_Boosting_looking_for_the_best_model\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"Gradient_Boosting_grid_search\"\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingRegressor()\n",
    "searcher = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_grid_search\") as run:\n",
    "    searcher.fit(X_train, y_train)\n",
    "    \n",
    "#mlflow.end_run()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2596ba1-0ef6-4185-9a0e-832790503880",
   "metadata": {},
   "source": [
    "# Probar inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e80bef-0bae-4fc5-86e6-e367d08afba6",
   "metadata": {},
   "source": [
    "**Probar inferencia mejor modelo de random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfa06a76-19fb-4559-a9dc-74f1a2d95458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real:  3550.0\n",
      "prediction:  3932.1369682485915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "\n",
    "model_name = \"Best_random_forest\"\n",
    "\n",
    "# logged_model = 'runs:/71428bebed2b4feb9635714ea3cdb562/model'\n",
    "model_production_uri = \"models:/{model_name}/production\".format(model_name=model_name)\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri=model_production_uri)\n",
    "loaded_model\n",
    "example_test = X_test.iloc[0].to_frame().T\n",
    "#print(example_test)\n",
    "print('real: ', y_test[0])\n",
    "print('prediction: ', loaded_model.predict(example_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc3e27-8169-4688-819f-cf526a3ed41a",
   "metadata": {},
   "source": [
    "**Probar inferencia mejor modelo de gradient boosting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2a43c2f-d525-4d1d-86d2-f24c299932fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real:  3550.0\n",
      "prediction:  3772.698561875597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://192.168.1.10:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "\n",
    "model_name = \"Best_gradient_boosting\"\n",
    "\n",
    "# logged_model = 'runs:/71428bebed2b4feb9635714ea3cdb562/model'\n",
    "model_production_uri = \"models:/{model_name}/production\".format(model_name=model_name)\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri=model_production_uri)\n",
    "loaded_model\n",
    "example_test = X_test.iloc[0].to_frame().T\n",
    "#print(example_test)\n",
    "print('real: ', y_test[0])\n",
    "print('prediction: ', loaded_model.predict(example_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ceb431e-e42a-49bf-8fcb-a58940910429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "Culmen Length (mm)    50.9\n",
       "Culmen Depth (mm)     19.1\n",
       "Flipper Length (mm)  196.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379ac668-d72e-4a23-9aab-1b34e5b5fa49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_gradient_boosting\n",
      "Best_random_forest\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "# List all registered models using search_registered_models\n",
    "registered_models = client.search_registered_models()\n",
    "\n",
    "# Print the names of the models\n",
    "for model in registered_models:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe79a57-d255-4898-8c67-4e5b743a02c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RegisteredModel: aliases={}, creation_timestamp=1741986372411, description='', last_updated_timestamp=1741986387485, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1741986372476, current_stage='Production', description='', last_updated_timestamp=1741986387485, name='Best_gradient_boosting', run_id='3d57fbf14a0c44a9b259d4283e1f0867', run_link='', source='s3://mlflows3/artifacts/3/3d57fbf14a0c44a9b259d4283e1f0867/artifacts/best_estimator', status='READY', status_message='', tags={}, user_id='', version='1'>], name='Best_gradient_boosting', tags={}>, <RegisteredModel: aliases={}, creation_timestamp=1741985542441, description='', last_updated_timestamp=1741986339075, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1741985542518, current_stage='Production', description='', last_updated_timestamp=1741985827221, name='Best_random_forest', run_id='0160c204d40248078897b9fac5b33c68', run_link='', source='s3://mlflows3/artifacts/2/0160c204d40248078897b9fac5b33c68/artifacts/best_estimator', status='READY', status_message='', tags={}, user_id='', version='1'>], name='Best_random_forest', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "print(registered_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345f140-9ce2-4dfe-bfcd-a237b8e4eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
